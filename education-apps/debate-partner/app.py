import streamlit as st
import google.generativeai as genai
import time

st.set_page_config(page_title="Virtual Debate Partner", page_icon="ğŸ—£ï¸")
st.title("ğŸ—£ï¸ Virtual Debate Partner (è™›æ“¬è¾¯è«–å°æ‰‹)")

# --- Config ---
api_key = st.sidebar.text_input("Enter Gemini API Key", type="password")
if api_key:
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-1.5-pro')

# --- Persona Selection ---
persona = st.sidebar.selectbox("é¸æ“‡å°æ‰‹é¢¨æ ¼", [
    "ç†æ€§ç§‘å­¸å®¶ (Focus on data & logic)",
    "æ¿€é€²ç’°ä¿ä¸»ç¾©è€… (Focus on ethics & impact)",
    "é­”é¬¼ä»£è¨€äºº (Always challenges your point)",
    "è˜‡æ ¼æ‹‰åº• (Asks deep philosophical questions)"
])

topic = st.sidebar.text_input("è¨­å®šè¾¯è«–é¡Œç›®", "æ ¸èƒ½ç™¼é›»æ˜¯å¦æ‡‰è©²è¢«æ¨å»£ï¼Ÿ")

# --- System Prompt ---
SYSTEM_PROMPT = f"""
ä½ ç¾åœ¨æ‰®æ¼”ä¸€ä½ã€Œ{persona}ã€ã€‚
è¾¯è«–é¡Œç›®æ˜¯ï¼šã€Œ{topic}ã€ã€‚
ä½ çš„ä»»å‹™æ˜¯ï¼š
1. å …å®šåœ°ç«™åœ¨ä½¿ç”¨è€…çš„å°ç«‹é¢ï¼ˆæˆ–æ ¹æ“šè§’è‰²è¨­å®šï¼‰ã€‚
2. æŒ‡å‡ºä½¿ç”¨è€…è«–é»ä¸­çš„é‚è¼¯è¬¬èª¤ã€‚
3. å¼•ç”¨æ•¸æ“šæˆ–ç†è«–ä¾†æ”¯æŒä½ çš„è§€é»ã€‚
4. ä¿æŒè¾¯è«–çš„å°ˆæ¥­æ€§ï¼Œä½†èªæ°£è¦ç¬¦åˆè§’è‰²è¨­å®šã€‚
5. æ¯æ¬¡å›è¦†æ§åˆ¶åœ¨ 150 å­—ä»¥å…§ï¼Œä¿æŒç¯€å¥ã€‚
"""

# --- Chat History ---
if "debate_history" not in st.session_state:
    st.session_state.debate_history = []

# --- UI ---
st.caption(f"ç•¶å‰é¡Œç›®ï¼š{topic}")

for msg in st.session_state.debate_history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

user_input = st.chat_input("æå‡ºä½ çš„è«–é»...")

if user_input:
    # User Turn
    st.session_state.debate_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.write(user_input)
    
    # AI Turn
    if api_key:
        with st.chat_message("assistant"):
            with st.spinner("å°æ‰‹æ­£åœ¨æ€è€ƒåé§é»..."):
                try:
                    # Construct prompt with history
                    full_prompt = [SYSTEM_PROMPT]
                    for m in st.session_state.debate_history:
                        full_prompt.append(f"{m['role']}: {m['content']}")
                    
                    response = model.generate_content(full_prompt)
                    st.write(response.text)
                    st.session_state.debate_history.append({"role": "assistant", "content": response.text})
                    
                    # Analysis (Mock or Real)
                    with st.expander("ğŸ“Š å³æ™‚é‚è¼¯åˆ†æ (AI Coach)"):
                        st.info("åˆ†æä½ çš„è«–é»å¼·åº¦...")
                        analysis_prompt = f"åˆ†æé€™å¥è©±çš„é‚è¼¯å¼·åº¦èˆ‡æ¼æ´ï¼š'{user_input}'ã€‚è«‹ç°¡çŸ­çµ¦å‡º 1 å€‹å„ªé»å’Œ 1 å€‹æ”¹é€²é»ã€‚"
                        analysis = model.generate_content(analysis_prompt)
                        st.markdown(analysis.text)

                except Exception as e:
                    st.error(f"API Error: {e}")
    else:
        st.warning("è«‹å…ˆè¼¸å…¥ API Key æ‰èƒ½é–‹å§‹è¾¯è«–ã€‚")
